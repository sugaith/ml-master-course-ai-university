{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rmotr](https://i.imgur.com/jiPp4hj.png)\n",
    "<hr style=\"margin-bottom: 40px;\">\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/7065401/39117173-a433bf6a-46e6-11e8-8a40-b4d4d6422493.jpg\"\n",
    "    style=\"width:300px; float: right; margin: 0 40px 40px 40px;\"></img>\n",
    "\n",
    "# Cleaning not-null values\n",
    "\n",
    "After dealing with many datasets I can tell you that \"missing data\" is not such a big deal. The best thing that can happen is to clearly see values like `np.nan`. The only thing you need to do is just use methods like `isnull` and `fillna`/`dropna` and pandas will take care of the rest.\n",
    "\n",
    "But sometimes, you can have invalid values that are not just \"missing data\" (`None`, or `nan`). For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![separator2](https://i.imgur.com/4gX5WFr.png)\n",
    "\n",
    "## Hands on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T22:45:04.101334Z",
     "start_time": "2023-12-03T22:45:03.658661100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T22:45:05.852870300Z",
     "start_time": "2023-12-03T22:45:05.828095700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Sex  Age\n0   M   29\n1   F   30\n2   F   24\n3   D  290\n4   ?   25",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>F</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>F</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>D</td>\n      <td>290</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>?</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Sex': ['M', 'F', 'F', 'D', '?'],\n",
    "    'Age': [29, 30, 24, 290, 25],\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous `DataFrame` doesn't have any \"missing value\", but clearly has invalid data. `290` doesn't seem like a valid age, and `D` and `?` don't correspond with any known sex category. How can you clean these not-missing, but clearly invalid values then?\n",
    "\n",
    "### Finding Unique Values\n",
    "\n",
    "The first step to clean invalid values is to **notice** them, then **identify** them and finally handle them appropriately (remove them, replace them, etc). Usually, for a \"categorical\" type of field (like Sex, which only takes values of a discrete set `('M', 'F')`), we start by analyzing the variety of values present. For that, we use the `unique()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T22:45:35.821215Z",
     "start_time": "2023-12-03T22:45:35.795890800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['M', 'F', 'D', '?'], dtype=object)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T22:46:44.091148700Z",
     "start_time": "2023-12-03T22:46:44.065780600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Sex\nF    2\nM    1\nD    1\n?    1\nName: count, dtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly if you see values like `'D'` or `'?'`, it'll immediately raise your attention. Now, what to do with them? Let's say you picked up the phone, called the survey company and they told you that `'D'` was a typo and it should actually be `F`. You can use the `replace` function to replace these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T22:48:01.756032200Z",
     "start_time": "2023-12-03T22:48:01.726511400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    M\n1    F\n2    F\n3    F\n4    ?\nName: Sex, dtype: object"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'].replace('D', 'F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can accept a dictionary of values to replace. For example, they also told you that there might be a few `'N's`, that should actually be `'M's`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T22:49:11.711222400Z",
     "start_time": "2023-12-03T22:49:11.661314200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    M\n1    F\n2    F\n3    F\n4    M\nName: Sex, dtype: object"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'].replace({'D': 'F', '?': 'M'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have many columns to replace, you could apply it at \"DataFrame level\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T22:49:17.424177100Z",
     "start_time": "2023-12-03T22:49:17.398633600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Sex  Age\n0   M   29\n1   F   30\n2   F   24\n3   F   29\n4   ?   25",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>F</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>F</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>F</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>?</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace({\n",
    "    'Sex': {\n",
    "        'D': 'F',\n",
    "        'N': 'M'\n",
    "    },\n",
    "    'Age': {\n",
    "        290: 29\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, I explicitly replaced 290 with 29 (assuming it was just an extra 0 entered at data-entry phase). But what if you'd like to remove all the extra 0s from the ages columns? (example, `150 > 15`, `490 > 49`).\n",
    "\n",
    "The first step would be to just set the limit of the \"not possible\" age. Is it 100? 120? Let's say that anything above 100 isn't credible for **our** dataset. We can then combine boolean selection with the operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T22:51:06.820421100Z",
     "start_time": "2023-12-03T22:51:05.249990100Z"
    }
   },
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(0    False\n1    False\n2    False\n3    False\n4    False\nName: Age, dtype: bool, 'Age')",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3652\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3653\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3654\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:153\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: '(0    False\n1    False\n2    False\n3    False\n4    False\nName: Age, dtype: bool, 'Age')' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mInvalidIndexError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df[df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAge\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m100\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAge\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3760\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3761\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mget_loc(key)\n\u001B[0;32m   3762\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3763\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3660\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3655\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3656\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3657\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3658\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3659\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m-> 3660\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n\u001B[0;32m   3661\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5737\u001B[0m, in \u001B[0;36mIndex._check_indexing_error\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   5733\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_indexing_error\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[0;32m   5734\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scalar(key):\n\u001B[0;32m   5735\u001B[0m         \u001B[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001B[39;00m\n\u001B[0;32m   5736\u001B[0m         \u001B[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001B[39;00m\n\u001B[1;32m-> 5737\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n",
      "\u001B[1;31mInvalidIndexError\u001B[0m: (0    False\n1    False\n2    False\n3    False\n4    False\nName: Age, dtype: bool, 'Age')"
     ]
    }
   ],
   "source": [
    "df[df['Age'] > 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can now just divide by 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T22:50:06.064479400Z",
     "start_time": "2023-12-03T22:50:06.037305900Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df['Age'] > 100, 'Age'] = df.loc[df['Age'] > 100, 'Age'] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T22:50:11.781731200Z",
     "start_time": "2023-12-03T22:50:11.753661600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Sex  Age\n0   M   29\n1   F   30\n2   F   24\n3   D   29\n4   ?   25",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>F</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>F</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>D</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>?</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![separator1](https://i.imgur.com/ZUWYTii.png)\n",
    "\n",
    "### Duplicates\n",
    "\n",
    "Checking duplicate values is extremely simple. It'll behave differently between Series and DataFrames. Let's start with Series. As an example, let's say we're throwing a fancy party and we're inviting Ambassadors from Europe. But can only invite one ambassador per country. This is our original list, and as you can see, both the UK and Germany have duplicated ambassadors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T22:56:14.338253300Z",
     "start_time": "2023-12-03T22:56:14.304462800Z"
    }
   },
   "outputs": [],
   "source": [
    "ambassadors = pd.Series([\n",
    "    'France',\n",
    "    'United Kingdom',\n",
    "    'United Kingdom',\n",
    "    'United Kingdom',\n",
    "    'Italy',\n",
    "    'Germany',\n",
    "    'Germany',\n",
    "    'Germany',\n",
    "], index=[\n",
    "    'Gérard Araud',\n",
    "    'Kim Darroch',\n",
    "    'Thiago da Silva',\n",
    "    'Peter Westmacott',\n",
    "    'Armando Varricchio',\n",
    "    'Peter Wittig',\n",
    "    'Peter Ammon',\n",
    "    'Klaus Scharioth '\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T22:56:16.901986900Z",
     "start_time": "2023-12-03T22:56:16.864949700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Gérard Araud                  France\nKim Darroch           United Kingdom\nThiago da Silva       United Kingdom\nPeter Westmacott      United Kingdom\nArmando Varricchio             Italy\nPeter Wittig                 Germany\nPeter Ammon                  Germany\nKlaus Scharioth              Germany\ndtype: object"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambassadors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two most important methods to deal with duplicates are `duplicated` (that will tell you which values are duplicates) and `drop_duplicates` (which will just get rid of duplicates):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T22:56:19.741985900Z",
     "start_time": "2023-12-03T22:56:19.715718700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Gérard Araud          False\nKim Darroch           False\nThiago da Silva        True\nPeter Westmacott       True\nArmando Varricchio    False\nPeter Wittig          False\nPeter Ammon            True\nKlaus Scharioth        True\ndtype: bool"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambassadors.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case `duplicated` didn't consider `'Kim Darroch'`, the first instance of the United Kingdom or `'Peter Wittig'` as duplicates. That's because, by default, it'll consider the first occurrence of the value as not-duplicate. You can change this behavior with the `keep` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T22:56:24.736400500Z",
     "start_time": "2023-12-03T22:56:24.707984200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Gérard Araud          False\nKim Darroch            True\nThiago da Silva        True\nPeter Westmacott      False\nArmando Varricchio    False\nPeter Wittig           True\nPeter Ammon            True\nKlaus Scharioth       False\ndtype: bool"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambassadors.duplicated(keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the result is \"flipped\", `'Kim Darroch'` and `'Peter Wittig'` (the first ambassadors of their countries) are considered duplicates, but `'Peter Westmacott'` and `'Klaus Scharioth'` are not duplicates. You can also choose to mark all of them as duplicates with `keep=False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T22:56:38.330081300Z",
     "start_time": "2023-12-03T22:56:38.305424100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Gérard Araud          False\nKim Darroch            True\nThiago da Silva        True\nPeter Westmacott       True\nArmando Varricchio    False\nPeter Wittig           True\nPeter Ammon            True\nKlaus Scharioth        True\ndtype: bool"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambassadors.duplicated(keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar method is `drop_duplicates`, which just excludes the duplicated values and also accepts the `keep` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T22:57:48.573336200Z",
     "start_time": "2023-12-03T22:57:48.548100600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Gérard Araud                  France\nKim Darroch           United Kingdom\nArmando Varricchio             Italy\nPeter Wittig                 Germany\ndtype: object"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambassadors.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gérard Araud                  France\n",
       "Peter Westmacott      United Kingdom\n",
       "Armando Varricchio             Italy\n",
       "Klaus Scharioth              Germany\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambassadors.drop_duplicates(keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gérard Araud          France\n",
       "Armando Varricchio     Italy\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambassadors.drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates in DataFrames\n",
    "\n",
    "Conceptually speaking, duplicates in a DataFrame happen at \"row\" level. Two rows with exactly the same values are considered to be duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.DataFrame({\n",
    "    'Name': [\n",
    "        'Kobe Bryant',\n",
    "        'LeBron James',\n",
    "        'Kobe Bryant',\n",
    "        'Carmelo Anthony',\n",
    "        'Kobe Bryant',\n",
    "    ],\n",
    "    'Pos': [\n",
    "        'SG',\n",
    "        'SF',\n",
    "        'SG',\n",
    "        'SF',\n",
    "        'SF'\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kobe Bryant</td>\n",
       "      <td>SG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kobe Bryant</td>\n",
       "      <td>SG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carmelo Anthony</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kobe Bryant</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name Pos\n",
       "0      Kobe Bryant  SG\n",
       "1     LeBron James  SF\n",
       "2      Kobe Bryant  SG\n",
       "3  Carmelo Anthony  SF\n",
       "4      Kobe Bryant  SF"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous DataFrame, we clearly see that Kobe is duplicated; but he appears with two different positions. What does `duplicated` say?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "4    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, conceptually, \"duplicated\" means \"all the column values should be duplicates\". We can customize this with the `subset` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "4     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players.duplicated(subset=['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the same rules of `keep` still apply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.duplicated(subset=['Name'], keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`drop_duplicates` takes the same parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.drop_duplicates(subset=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "players.drop_duplicates(subset=['Name'], keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![separator1](https://i.imgur.com/ZUWYTii.png)\n",
    "\n",
    "### Text Handling\n",
    "\n",
    "Cleaning text values can be incredibly hard. Invalid text values involves, 99% of the time, mistyping, which is completely unpredictable and doesn't follow any pattern. Thankfully, it's not so common these days, where data-entry tasks have been replaced by machines. Still, let's explore the most common cases:\n",
    "\n",
    "### Splitting Columns\n",
    "\n",
    "The result of a survey is loaded and this is what you get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:07:25.081893100Z",
     "start_time": "2023-12-03T23:07:25.057509100Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Data': [\n",
    "        '1987_M_US _1',\n",
    "        '1990?_M_UK_1',\n",
    "        '1992_F_US_2',\n",
    "        '1970?_M_   IT_1',\n",
    "        '1985_F_I  T_2'\n",
    "]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:07:28.145121800Z",
     "start_time": "2023-12-03T23:07:28.116483100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "              Data\n0     1987_M_US _1\n1     1990?_M_UK_1\n2      1992_F_US_2\n3  1970?_M_   IT_1\n4    1985_F_I  T_2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1987_M_US _1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1990?_M_UK_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1992_F_US_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1970?_M_   IT_1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1985_F_I  T_2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You know that the single columns represent the values \"year, Sex, Country and number of children\", but it's all been grouped in the same column and separated by an underscore. Pandas has a convenient method named `split` that we can use in these situations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:08:40.986187100Z",
     "start_time": "2023-12-03T23:08:40.935169700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0       1987 M US  1\n1       1990? M UK 1\n2        1992 F US 2\n3    1970? M    IT 1\n4      1985 F I  T 2\nName: Data, dtype: object"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Data'].str.replace('_', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>M</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990?</td>\n",
       "      <td>M</td>\n",
       "      <td>UK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992</td>\n",
       "      <td>F</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970?</td>\n",
       "      <td>M</td>\n",
       "      <td>IT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>F</td>\n",
       "      <td>I  T</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1      2  3\n",
       "0   1987  M    US   1\n",
       "1  1990?  M     UK  1\n",
       "2   1992  F     US  2\n",
       "3  1970?  M     IT  1\n",
       "4   1985  F   I  T  2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Data'].str.split('_', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:09:16.208755900Z",
     "start_time": "2023-12-03T23:09:16.179757500Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df['Data'].str.split('_', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:09:16.986637300Z",
     "start_time": "2023-12-03T23:09:16.956969900Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns = ['Year', 'Sex', 'Country', 'No Children']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check which columns contain a given value with the `contains` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T23:09:18.207365Z",
     "start_time": "2023-12-03T23:09:18.158934300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Year Sex Country No Children\n0   1987   M     US            1\n1  1990?   M      UK           1\n2   1992   F      US           2\n3  1970?   M      IT           1\n4   1985   F    I  T           2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Sex</th>\n      <th>Country</th>\n      <th>No Children</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1987</td>\n      <td>M</td>\n      <td>US</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1990?</td>\n      <td>M</td>\n      <td>UK</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1992</td>\n      <td>F</td>\n      <td>US</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1970?</td>\n      <td>M</td>\n      <td>IT</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1985</td>\n      <td>F</td>\n      <td>I  T</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:09:21.410568200Z",
     "start_time": "2023-12-03T23:09:21.380938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    False\n1     True\n2    False\n3     True\n4    False\nName: Year, dtype: bool"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Year'].str.contains('\\?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`contains`](http://pandas.pydata.org/pandas-docs/version/0.22.0/generated/pandas.Series.str.contains.html) takes a regex/pattern as first value, so we need to escape the `?` symbol as it has a special meaning for these patterns. Regular letters don't need escaping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:09:54.682403Z",
     "start_time": "2023-12-03T23:09:54.657385800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0     True\n1     True\n2     True\n3    False\n4    False\nName: Country, dtype: bool"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Country'].str.contains('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing blank spaces (like in `'US '` or `'I  T'` can be achieved with `strip` (`lstrip` and `rstrip` also exist) or just `replace`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T23:11:09.786230800Z",
     "start_time": "2023-12-03T23:11:09.755045800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0      US\n1      UK\n2      US\n3      IT\n4    I  T\nName: Country, dtype: object"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Country'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    US\n",
       "1    UK\n",
       "2    US\n",
       "3    IT\n",
       "4    IT\n",
       "Name: Country, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Country'].str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we said, `replace` and `contains` take regex patterns, which can make it easier to replace values in bulk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T23:13:56.733094400Z",
     "start_time": "2023-12-03T23:13:56.674716100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0     1987\n1    1990?\n2     1992\n3    1970?\n4     1985\nName: Year, dtype: object"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Year'].str.replace(r'(?P<year>\\d{4})\\?', '^^')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, be warned:\n",
    "\n",
    "> Some people, when confronted with a problem, think \"I know, I'll use regular expressions.\" Now they have two problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, all these string/text-related operations are applied over the `str` attribute of the series. That's because they have a special place in Series handling and you can read more about it [here](https://pandas.pydata.org/pandas-docs/stable/text.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![separator2](https://i.imgur.com/4gX5WFr.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
